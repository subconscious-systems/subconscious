{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Started with Subconscious\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/subconscious-systems/subconscious/blob/main/examples/getting_started_notebook/getting_started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "---\n",
        "\n",
        "Welcome! This notebook will walk you through **Subconscious** â€” a long-horizon reasoning engine that chains complex reasoning steps, uses tools, and handles tasks that require extended planning.\n",
        "\n",
        "**No prior experience required.** We'll go step by step:\n",
        "\n",
        "1. Install the SDK\n",
        "2. Set up your API key\n",
        "3. Run your first agent\n",
        "4. Give the agent tools (web search, etc.)\n",
        "5. Get structured output using Pydantic\n",
        "6. Try different engines\n",
        "\n",
        "Let's go!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install the SDK\n",
        "\n",
        "Run the cell below to install the Subconscious Python SDK. This is the only dependency you need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install subconscious-sdk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Set Your API Key\n",
        "\n",
        "You'll need a Subconscious API key. If you don't have one yet:\n",
        "\n",
        "1. Go to [subconscious.dev/platform](https://www.subconscious.dev/platform)\n",
        "2. Sign up / log in\n",
        "3. Copy your API key\n",
        "\n",
        "**Pick the method that matches your environment:**\n",
        "\n",
        "- **Google Colab** â€” the cell below will try Colab's built-in Secrets manager first. Add a secret named `SUBCONSCIOUS_API_KEY` via the ðŸ”‘ icon in the left sidebar.\n",
        "- **Local Jupyter** â€” it will fall back to a `getpass` prompt so your key stays hidden.\n",
        "- **Anywhere else** â€” you can paste your key directly into the string below (just don't commit the notebook with it!)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "api_key = None\n",
        "\n",
        "# 1) Colab Secrets (recommended for Colab)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    api_key = userdata.get(\"SUBCONSCIOUS_API_KEY\")\n",
        "    print(\"Loaded API key from Colab Secrets.\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# 2) Already set in environment\n",
        "if not api_key:\n",
        "    api_key = os.environ.get(\"SUBCONSCIOUS_API_KEY\")\n",
        "    if api_key:\n",
        "        print(\"Loaded API key from environment variable.\")\n",
        "\n",
        "# 3) Interactive prompt (works in Jupyter / terminals)\n",
        "if not api_key:\n",
        "    import getpass\n",
        "    api_key = getpass.getpass(\"Enter your Subconscious API key: \")\n",
        "\n",
        "# 4) Last resort â€” paste it here (don't commit this!)\n",
        "# api_key = \"sk-...\"\n",
        "\n",
        "os.environ[\"SUBCONSCIOUS_API_KEY\"] = api_key\n",
        "print(\"API key is set.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "API key is set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize the Client\n",
        "\n",
        "Now we create a `Subconscious` client. This is the object you'll use for every API call."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from subconscious import Subconscious\n",
        "\n",
        "client = Subconscious(api_key=os.environ[\"SUBCONSCIOUS_API_KEY\"])\n",
        "\n",
        "print(\"Client ready!\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Client ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Your First Agent Run (No Tools)\n",
        "\n",
        "The simplest thing you can do is give the agent a plain instruction and let it reason on its own â€” no tools, no extra config.\n",
        "\n",
        "Key parameters:\n",
        "- **`engine`** â€” which model to use (we'll start with `\"tim-gpt\"`)\n",
        "- **`input.instructions`** â€” what you want the agent to do\n",
        "- **`options.await_completion`** â€” wait for the full answer before returning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run = client.run(\n",
        "    engine=\"tim-gpt\",\n",
        "    input={\n",
        "        \"instructions\": \"Explain what an API is in 3 sentences, as if I'm 10 years old.\",\n",
        "    },\n",
        "    options={\"await_completion\": True},\n",
        ")\n",
        "\n",
        "print(run.result.answer)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "An API is like a menu at a restaurant, showing you what dishes you can order and how to ask for them. When you make a request, the kitchen (which is like another computer or app) prepares what you asked for and gives it back, all without you needing to know how the kitchen works. In the same way, an API helps different programs talk to each other and share information, while keeping things easy and organized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Try It Yourself\n",
        "\n",
        "Change the `instructions` string below to anything you want and run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_question = \"What is the difference between machine learning and deep learning?\"\n",
        "\n",
        "run = client.run(\n",
        "    engine=\"tim-gpt\",\n",
        "    input={\"instructions\": my_question},\n",
        "    options={\"await_completion\": True},\n",
        ")\n",
        "\n",
        "print(run.result.answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Using Platform Tools\n",
        "\n",
        "Agents become much more powerful when you give them **tools**. Subconscious ships with built-in \"platform tools\" that require zero setup.\n",
        "\n",
        "Here are some popular ones:\n",
        "\n",
        "| Tool | API Name | What it does |\n",
        "|------|----------|--------------|\n",
        "| Fast Search | `fast_search` | Quick factual lookups |\n",
        "| Web Search | `web_search` | Detailed web research |\n",
        "| News Search | `news_search` | Search news articles |\n",
        "| Page Reader | `page_reader` | Read a webpage URL |\n",
        "\n",
        "To give an agent a tool, pass it in the `tools` list. Let's try `fast_search`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run = client.run(\n",
        "    engine=\"tim-gpt\",\n",
        "    input={\n",
        "        \"instructions\": \"What is the current population of Tokyo?\",\n",
        "        \"tools\": [\n",
        "            {\"type\": \"platform\", \"id\": \"fast_search\"}\n",
        "        ],\n",
        "    },\n",
        "    options={\"await_completion\": True},\n",
        ")\n",
        "\n",
        "print(run.result.answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multiple Tools at Once\n",
        "\n",
        "You can give the agent several tools and it will decide which ones to use. Here we combine `web_search` and `news_search` so the agent can do thorough research:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run = client.run(\n",
        "    engine=\"tim-gpt\",\n",
        "    input={\n",
        "        \"instructions\": \"Give me a brief summary of the biggest AI news from this week.\",\n",
        "        \"tools\": [\n",
        "            {\"type\": \"platform\", \"id\": \"web_search\"},\n",
        "            {\"type\": \"platform\", \"id\": \"news_search\"},\n",
        "        ],\n",
        "    },\n",
        "    options={\"await_completion\": True},\n",
        ")\n",
        "\n",
        "print(run.result.answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Structured Output with Pydantic\n",
        "\n",
        "Sometimes you don't want a free-text answer â€” you want **structured data** you can use in code (JSON with specific fields).\n",
        "\n",
        "Subconscious supports this via [Pydantic](https://docs.pydantic.dev/) models. You define a schema and the agent's answer will match it.\n",
        "\n",
        "Here's an example that analyzes the sentiment of a piece of text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "class SentimentAnalysis(BaseModel):\n",
        "    sentiment: str        # e.g. \"positive\", \"negative\", \"neutral\"\n",
        "    confidence: float     # 0.0 to 1.0\n",
        "    keywords: list[str]   # key words that influenced the sentiment\n",
        "\n",
        "\n",
        "text_to_analyze = \"I absolutely loved the new movie! The acting was superb and the storyline kept me on the edge of my seat.\"\n",
        "\n",
        "run = client.run(\n",
        "    engine=\"tim-gpt\",\n",
        "    input={\n",
        "        \"instructions\": f\"Analyze the sentiment of this text: '{text_to_analyze}'\",\n",
        "        \"answerFormat\": SentimentAnalysis,\n",
        "    },\n",
        "    options={\"await_completion\": True},\n",
        ")\n",
        "\n",
        "result = run.result.answer\n",
        "print(f\"Sentiment:  {result['sentiment']}\")\n",
        "print(f\"Confidence: {result['confidence']}\")\n",
        "print(f\"Keywords:   {result['keywords']}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Streaming â€” See Results in Real Time\n",
        "\n",
        "Instead of waiting for the full run to complete with `client.run()`, you can use **streaming** to receive content as the agent produces it. This is great for long tasks where you want to see thoughts and the answer as they appear.\n",
        "\n",
        "Call `client.stream()` with the same `engine` and `input` you'd use for `run`. You get an iterator of events:\n",
        "\n",
        "- **`delta`** â€” a chunk of content (reasoning and answer are streamed as JSON; we accumulate and print the answer as it arrives)\n",
        "- **`done`** â€” the run finished\n",
        "- **`error`** â€” something went wrong\n",
        "\n",
        "Run the cell below to see the answer stream in live."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "\n",
        "# Same client and setup as before â€” run the API key and \"Initialize the Client\" cells first!\n",
        "stream = client.stream(\n",
        "    engine=\"tim-gpt\",\n",
        "    input={\n",
        "        \"instructions\": \"What is 17 * 24? Reply with just the number.\",\n",
        "        \"tools\": [],  # no tools needed for this\n",
        "    },\n",
        ")\n",
        "\n",
        "full_content = \"\"\n",
        "for event in stream:\n",
        "    if event.type == \"delta\" and event.content:\n",
        "        full_content += event.content\n",
        "        # Print content as it arrives (you'll see raw JSON stream; the final answer is in the \"answer\" field)\n",
        "        print(event.content, end=\"\", flush=True)\n",
        "    elif event.type == \"done\":\n",
        "        print(\"\\n\\n--- Stream complete ---\")\n",
        "        # Parse and show the final answer from the streamed JSON\n",
        "        try:\n",
        "            data = json.loads(full_content)\n",
        "            if isinstance(data, dict) and \"answer\" in data:\n",
        "                print(\"Answer:\", data[\"answer\"])\n",
        "        except json.JSONDecodeError:\n",
        "            pass\n",
        "    elif event.type == \"error\":\n",
        "        print(f\"\\nError: {getattr(event, 'message', 'Unknown error')}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Another Structured Example â€” Extracting Facts\n",
        "\n",
        "Let's combine tools and structured output. The agent will search the web and return structured data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class CompanyInfo(BaseModel):\n",
        "    name: str\n",
        "    founded: str\n",
        "    headquarters: str\n",
        "    ceo: str\n",
        "    industry: str\n",
        "\n",
        "\n",
        "run = client.run(\n",
        "    engine=\"tim-gpt\",\n",
        "    input={\n",
        "        \"instructions\": \"Look up basic facts about SpaceX.\",\n",
        "        \"tools\": [{\"type\": \"platform\", \"id\": \"fast_search\"}],\n",
        "        \"answerFormat\": CompanyInfo,\n",
        "    },\n",
        "    options={\"await_completion\": True},\n",
        ")\n",
        "\n",
        "info = run.result.answer\n",
        "for field, value in info.items():\n",
        "    print(f\"{field:>15}: {value}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Trying Different Engines\n",
        "\n",
        "Subconscious offers several engines â€” each optimized for different trade-offs:\n",
        "\n",
        "| Engine | API Name | Best for |\n",
        "|--------|----------|----------|\n",
        "| TIM | `tim` | General-purpose, wide range of tasks |\n",
        "| TIM-Edge | `tim-edge` | Fast + efficient, great with search tools |\n",
        "| TIMINI | `timini` | Complex reasoning, backed by Gemini-3 Flash |\n",
        "| TIM-GPT | `tim-gpt` | Complex reasoning, backed by GPT-4.1 |\n",
        "| TIM-GPT-Heavy | `tim-gpt-heavy` | Maximum capability, backed by GPT-5.2 |\n",
        "\n",
        "Just change the `engine` parameter to try a different one:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "engines_to_try = [\"tim\", \"tim-edge\", \"tim-gpt\"]\n",
        "question = \"In one sentence, what causes the Northern Lights?\"\n",
        "\n",
        "for engine in engines_to_try:\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"Engine: {engine}\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "\n",
        "    run = client.run(\n",
        "        engine=engine,\n",
        "        input={\n",
        "            \"instructions\": question,\n",
        "            \"tools\": [{\"type\": \"platform\", \"id\": \"fast_search\"}],\n",
        "        },\n",
        "        options={\"await_completion\": True},\n",
        "    )\n",
        "\n",
        "    print(run.result.answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Peeking Under the Hood â€” Reasoning Steps\n",
        "\n",
        "Every Subconscious run includes a `reasoning` field that shows the agent's step-by-step thought process, including which tools it called and what it found.\n",
        "\n",
        "This is incredibly useful for understanding *how* the agent arrived at its answer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "\n",
        "run = client.run(\n",
        "    engine=\"tim-gpt\",\n",
        "    input={\n",
        "        \"instructions\": \"Who won the first ever FIFA World Cup and where was it held?\",\n",
        "        \"tools\": [{\"type\": \"platform\", \"id\": \"fast_search\"}],\n",
        "    },\n",
        "    options={\"await_completion\": True},\n",
        ")\n",
        "\n",
        "print(\"ANSWER:\")\n",
        "print(run.result.answer)\n",
        "print(\"\\nREASONING STEPS:\")\n",
        "print(json.dumps(run.result.reasoning, indent=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What's Next?\n",
        "\n",
        "You've now covered the core building blocks of Subconscious! Here are some ideas for what to explore next:\n",
        "\n",
        "- **Custom function tools** â€” connect the agent to your own HTTP endpoints ([docs](https://docs.subconscious.dev/core-concepts/tools))\n",
        "- **MCP tools** â€” plug into Model Context Protocol servers\n",
        "- **Streaming** â€” get results in real-time as the agent works\n",
        "- **More examples** â€” check out the [examples folder](https://github.com/subconscious-systems/subconscious/tree/main/examples) for full projects\n",
        "\n",
        "### Useful Links\n",
        "\n",
        "| Resource | Link |\n",
        "|----------|------|\n",
        "| Documentation | [docs.subconscious.dev](https://docs.subconscious.dev) |\n",
        "| API Reference | [docs.subconscious.dev/api-reference](https://docs.subconscious.dev/api-reference/introduction) |\n",
        "| Platform (get API key) | [subconscious.dev/platform](https://www.subconscious.dev/platform) |\n",
        "| GitHub | [github.com/subconscious-systems/subconscious](https://github.com/subconscious-systems/subconscious) |\n",
        "\n",
        "Happy building!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}